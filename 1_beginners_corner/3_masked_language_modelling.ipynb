{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b274b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-12-22 19:27:47--  https://lazyprogrammer.me/course_files/nlp/bbc_text_cls.csv\n",
      "Resolving lazyprogrammer.me (lazyprogrammer.me)... 2606:4700:3031::6815:17d2, 2606:4700:3030::ac43:d5a6, 104.21.23.210, ...\n",
      "Connecting to lazyprogrammer.me (lazyprogrammer.me)|2606:4700:3031::6815:17d2|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5085081 (4.8M) [text/csv]\n",
      "Saving to: 'bbc_text_cls.csv'\n",
      "\n",
      "bbc_text_cls.csv    100%[===================>]   4.85M  4.44MB/s    in 1.1s    \n",
      "\n",
      "2025-12-22 19:27:49 (4.44 MB/s) - 'bbc_text_cls.csv' saved [5085081/5085081]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/shivamkushwaha/bbc-full-text-document-classification\n",
    "!wget -nc https://lazyprogrammer.me/course_files/nlp/bbc_text_cls.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a2ee897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import textwrap\n",
    "from pprint import pprint\n",
    "\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53b92e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bbc_text_cls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d553f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    labels\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...  business"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0ba15a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business', 'entertainment', 'politics', 'sport', 'tech'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = set(df['labels'])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37f9b364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a label\n",
    "label = 'business'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e9e6398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Ad sales boost Time Warner profit\\n\\nQuarterly...\n",
       "1    Dollar gains on Greenspan speech\\n\\nThe dollar...\n",
       "2    Yukos unit buyer faces loan claim\\n\\nThe owner...\n",
       "3    High fuel prices hit BA's profits\\n\\nBritish A...\n",
       "4    Pernod takeover talk lifts Domecq\\n\\nShares in...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = df[df['labels'] == label]['text']\n",
    "texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23ae3b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de8190a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.choice(texts.shape[0])\n",
    "doc = texts.iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69ffbb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bombardier chief to leave company\n",
      "\n",
      "Shares in train and plane-making\n",
      "giant Bombardier have fallen to a 10-year low following the departure\n",
      "of its chief executive and two members of the board.\n",
      "\n",
      "Paul Tellier,\n",
      "who was also Bombardier's president, left the company amid an ongoing\n",
      "restructuring.  Laurent Beaudoin, part of the family that controls the\n",
      "Montreal-based firm, will take on the role of CEO under a newly\n",
      "created management structure.  Analysts said the resignations seem to\n",
      "have stemmed from a boardroom dispute.  Under Mr Tellier's tenure at\n",
      "the company, which began in January 2003, plans to cut the worldwide\n",
      "workforce of 75,000 by almost a third by 2006 were announced.  The\n",
      "firm's snowmobile division and defence services unit were also sold\n",
      "and Bombardier started the development of a new aircraft seating 110\n",
      "to 135 passengers.\n",
      "\n",
      "Mr Tellier had indicated he wanted to stay at the\n",
      "world's top train maker and third largest manufacturer of civil\n",
      "aircraft until the restructuring was complete.  But Bombardier has\n",
      "been faced with a declining share price and profits.  Earlier this\n",
      "month the firm said it earned $10m (Â£19.2m) in the third quarter, down\n",
      "from a profit of $133m a year ago.  \"I understand the board's concern\n",
      "that I would not be there for the long-term and the need to develop\n",
      "and execute strategies, and the need to reshape the management\n",
      "structure at this time,\" Mr Tellier said in a statement on Monday.\n",
      "Bombardier said restructuring plans drawn up by Mr Tellier's would\n",
      "continue to be implemented.  Shares in Bombardier lost 65 Canadian\n",
      "cents or 25% on the news to 1.90 Canadian dollars before rallying to\n",
      "2.20 Canadian dollars.\n"
     ]
    }
   ],
   "source": [
    "print(textwrap.fill(doc, replace_whitespace=False, fix_sentence_endings=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51eaa875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilroberta-base and revision ec58a5b (https://huggingface.co/distilbert/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92863585410f4ce6911eaa2df65e3f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef0b1eee21c40cf875ba948080ee8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/331M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8592a20fd147f0b2169376207a5f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a948696fc2734f4e9c40e63a8ee59899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47aee592deb545bf9f1b22f1cef294f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501f964fc15e48758e865b01501b0b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlm = pipeline('fill-mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54c4af82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.0695083811879158,\n",
       "  'token': 633,\n",
       "  'token_str': ' job',\n",
       "  'sequence': 'Bombardier chief to leave job'},\n",
       " {'score': 0.06693071871995926,\n",
       "  'token': 1470,\n",
       "  'token_str': ' France',\n",
       "  'sequence': 'Bombardier chief to leave France'},\n",
       " {'score': 0.052735306322574615,\n",
       "  'token': 558,\n",
       "  'token_str': ' office',\n",
       "  'sequence': 'Bombardier chief to leave office'},\n",
       " {'score': 0.025823045521974564,\n",
       "  'token': 2201,\n",
       "  'token_str': ' Paris',\n",
       "  'sequence': 'Bombardier chief to leave Paris'},\n",
       " {'score': 0.021368546411395073,\n",
       "  'token': 896,\n",
       "  'token_str': ' Canada',\n",
       "  'sequence': 'Bombardier chief to leave Canada'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm('Bombardier chief to leave <mask>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e502ec20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.6640955805778503,\n",
       "  'token': 11016,\n",
       "  'token_str': ' Airbus',\n",
       "  'sequence': 'Shares in Airbus and plane-making giant Bombardier have fallen to a 10-year low following the departure of its chief executive and two members of the board.'},\n",
       " {'score': 0.2614656686782837,\n",
       "  'token': 6722,\n",
       "  'token_str': ' Boeing',\n",
       "  'sequence': 'Shares in Boeing and plane-making giant Bombardier have fallen to a 10-year low following the departure of its chief executive and two members of the board.'},\n",
       " {'score': 0.023635320365428925,\n",
       "  'token': 15064,\n",
       "  'token_str': ' aerospace',\n",
       "  'sequence': 'Shares in aerospace and plane-making giant Bombardier have fallen to a 10-year low following the departure of its chief executive and two members of the board.'},\n",
       " {'score': 0.014581810683012009,\n",
       "  'token': 8537,\n",
       "  'token_str': ' airlines',\n",
       "  'sequence': 'Shares in airlines and plane-making giant Bombardier have fallen to a 10-year low following the departure of its chief executive and two members of the board.'},\n",
       " {'score': 0.005284355953335762,\n",
       "  'token': 9848,\n",
       "  'token_str': ' aviation',\n",
       "  'sequence': 'Shares in aviation and plane-making giant Bombardier have fallen to a 10-year low following the departure of its chief executive and two members of the board.'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Shares in <mask> and plane-making ' + \\\n",
    "  'giant Bombardier have fallen to a 10-year low following the departure ' + \\\n",
    "  'of its chief executive and two members of the board.'\n",
    "\n",
    "mlm(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "892622f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.5513915419578552,\n",
      "  'sequence': 'Shares in train and plane-making giant Bombardier have fallen '\n",
      "              'to a 10-year low following the resignation of its chief '\n",
      "              'executive and two members of the board.',\n",
      "  'token': 6985,\n",
      "  'token_str': ' resignation'},\n",
      " {'score': 0.21090513467788696,\n",
      "  'sequence': 'Shares in train and plane-making giant Bombardier have fallen '\n",
      "              'to a 10-year low following the departure of its chief executive '\n",
      "              'and two members of the board.',\n",
      "  'token': 5824,\n",
      "  'token_str': ' departure'},\n",
      " {'score': 0.13042031228542328,\n",
      "  'sequence': 'Shares in train and plane-making giant Bombardier have fallen '\n",
      "              'to a 10-year low following the departures of its chief '\n",
      "              'executive and two members of the board.',\n",
      "  'token': 25624,\n",
      "  'token_str': ' departures'},\n",
      " {'score': 0.03651556745171547,\n",
      "  'sequence': 'Shares in train and plane-making giant Bombardier have fallen '\n",
      "              'to a 10-year low following the dismissal of its chief executive '\n",
      "              'and two members of the board.',\n",
      "  'token': 14289,\n",
      "  'token_str': ' dismissal'},\n",
      " {'score': 0.014638726599514484,\n",
      "  'sequence': 'Shares in train and plane-making giant Bombardier have fallen '\n",
      "              'to a 10-year low following the firing of its chief executive '\n",
      "              'and two members of the board.',\n",
      "  'token': 5834,\n",
      "  'token_str': ' firing'}]\n"
     ]
    }
   ],
   "source": [
    "text = 'Shares in train and plane-making ' + \\\n",
    "  'giant Bombardier have fallen to a 10-year low following the <mask> ' + \\\n",
    "  'of its chief executive and two members of the board.'\n",
    "\n",
    "pprint(mlm(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "487040cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.9897111654281616,\n",
      "  'sequence': 'Shares in train and plane-making giant Bombardier have fallen '\n",
      "              'to a 10-year low following the departure of its chief executive '\n",
      "              'and two members of the board.',\n",
      "  'token': 1031,\n",
      "  'token_str': ' executive'},\n",
      " {'score': 0.006391073111444712,\n",
      "  'sequence': 'Shares in train and plane-making giant Bombardier have fallen '\n",
      "              'to a 10-year low following the departure of its chief '\n",
      "              'executives and two members of the board.',\n",
      "  'token': 4585,\n",
      "  'token_str': ' executives'},\n",
      " {'score': 0.0016239373944699764,\n",
      "  'sequence': 'Shares in train and plane-making giant Bombardier have fallen '\n",
      "              'to a 10-year low following the departure of its chief economist '\n",
      "              'and two members of the board.',\n",
      "  'token': 7473,\n",
      "  'token_str': ' economist'},\n",
      " {'score': 0.0007142710965126753,\n",
      "  'sequence': 'Shares in train and plane-making giant Bombardier have fallen '\n",
      "              'to a 10-year low following the departure of its chief officer '\n",
      "              'and two members of the board.',\n",
      "  'token': 1036,\n",
      "  'token_str': ' officer'},\n",
      " {'score': 0.00042171869426965714,\n",
      "  'sequence': 'Shares in train and plane-making giant Bombardier have fallen '\n",
      "              'to a 10-year low following the departure of its chief engineer '\n",
      "              'and two members of the board.',\n",
      "  'token': 8083,\n",
      "  'token_str': ' engineer'}]\n"
     ]
    }
   ],
   "source": [
    "text = 'Shares in train and plane-making ' + \\\n",
    "  'giant Bombardier have fallen to a 10-year low following the departure ' + \\\n",
    "  'of its chief <mask> and two members of the board.'\n",
    "\n",
    "pprint(mlm(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80cc9f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.9420543909072876,\n",
      "  'sequence': 'Shares in train and plane-making giant Bombardier have fallen '\n",
      "              'to a 10-year low following the departure of its chief executive '\n",
      "              'and two members of the board.',\n",
      "  'token': 453,\n",
      "  'token_str': ' members'},\n",
      " {'score': 0.032231640070676804,\n",
      "  'sequence': 'Shares in train and plane-making giant Bombardier have fallen '\n",
      "              'to a 10-year low following the departure of its chief executive '\n",
      "              'and two thirds of the board.',\n",
      "  'token': 29193,\n",
      "  'token_str': ' thirds'},\n",
      " {'score': 0.011233003810048103,\n",
      "  'sequence': 'Shares in train and plane-making giant Bombardier have fallen '\n",
      "              'to a 10-year low following the departure of its chief executive '\n",
      "              'and two directors of the board.',\n",
      "  'token': 5392,\n",
      "  'token_str': ' directors'},\n",
      " {'score': 0.0030280654318630695,\n",
      "  'sequence': 'Shares in train and plane-making giant Bombardier have fallen '\n",
      "              'to a 10-year low following the departure of its chief executive '\n",
      "              'and two chairs of the board.',\n",
      "  'token': 10826,\n",
      "  'token_str': ' chairs'},\n",
      " {'score': 0.001954793930053711,\n",
      "  'sequence': 'Shares in train and plane-making giant Bombardier have fallen '\n",
      "              'to a 10-year low following the departure of its chief executive '\n",
      "              'and two chiefs of the board.',\n",
      "  'token': 15201,\n",
      "  'token_str': ' chiefs'}]\n"
     ]
    }
   ],
   "source": [
    "text = 'Shares in train and plane-making ' + \\\n",
    "  'giant Bombardier have fallen to a 10-year low following the departure ' + \\\n",
    "  'of its chief executive and two <mask> of the board.'\n",
    "\n",
    "pprint(mlm(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8004fcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilroberta-base and revision ec58a5b (https://huggingface.co/distilbert/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Bombardier chief to leave company\n",
      "\n",
      "Shares in train and plane-making giant Bombardier have fallen to a 10-year low following the departure of its chief executive and two members of the board.\n",
      "\n",
      "Modified: Jet agrees to join board\n",
      "\n",
      "Shares in train and plane-making giant Airbus have fallen to a 10-year low following the departure of its chief executive and two members of the board.\n",
      "\n",
      "Replacements made:\n",
      "  'chief' -> 'chief' (TF-IDF: 0.2981)\n",
      "  'Bombardier' -> 'Airbus' (TF-IDF: 0.2981)\n",
      "  'Shares' -> 'Shares' (TF-IDF: 0.1491)\n",
      "  'company' -> 'board' (TF-IDF: 0.1491)\n",
      "  'leave' -> 'join' (TF-IDF: 0.1491)\n",
      "  'chief' -> 'agrees' (TF-IDF: 0.2981)\n",
      "  'Bombardier' -> 'Jet' (TF-IDF: 0.2981)\n"
     ]
    }
   ],
   "source": [
    "# Exercise: Write a function that automatically masks and replaces words\n",
    "# in a whole document. You might choose which words to replace based on some\n",
    "# statistic, e.g. TF-IDF.\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "def auto_mask_replace(document, mlm_pipeline, corpus=None, num_words_to_replace=None, \n",
    "                     tfidf_threshold=None, top_k=1, min_word_length=3, \n",
    "                     exclude_stopwords=True, preserve_case=True):\n",
    "    \"\"\"\n",
    "    Automatically masks and replaces words in a document based on TF-IDF scores.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    document : str\n",
    "        The input document to process\n",
    "    mlm_pipeline : pipeline\n",
    "        The fill-mask pipeline from transformers\n",
    "    corpus : list of str, optional\n",
    "        Corpus of documents for IDF calculation. If None, uses only the input document.\n",
    "    num_words_to_replace : int, optional\n",
    "        Number of top TF-IDF words to replace. If None, uses tfidf_threshold.\n",
    "    tfidf_threshold : float, optional\n",
    "        Minimum TF-IDF score to replace a word. If None, uses num_words_to_replace.\n",
    "    top_k : int, default=1\n",
    "        Which prediction to use from MLM (1 = highest score, 2 = second highest, etc.)\n",
    "    min_word_length : int, default=3\n",
    "        Minimum word length to consider for replacement\n",
    "    exclude_stopwords : bool, default=True\n",
    "        Whether to exclude common stopwords\n",
    "    preserve_case : bool, default=True\n",
    "        Whether to preserve original word case in replacement\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str : The document with words replaced\n",
    "    dict : Information about replacements made\n",
    "    \"\"\"\n",
    "    \n",
    "    # Simple stopwords list (can be expanded)\n",
    "    stopwords = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', \n",
    "                 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', \n",
    "                 'been', 'have', 'has', 'had', 'do', 'does', 'did', 'will', \n",
    "                 'would', 'could', 'should', 'may', 'might', 'must', 'can'}\n",
    "    \n",
    "    # Tokenize document into words while preserving positions\n",
    "    words = re.findall(r'\\b\\w+\\b', document)\n",
    "    word_positions = []\n",
    "    current_pos = 0\n",
    "    \n",
    "    for word in words:\n",
    "        pos = document.find(word, current_pos)\n",
    "        word_positions.append((word, pos, pos + len(word)))\n",
    "        current_pos = pos + len(word)\n",
    "    \n",
    "    # Filter words\n",
    "    filtered_words = []\n",
    "    filtered_positions = []\n",
    "    for word, start, end in word_positions:\n",
    "        if len(word) >= min_word_length:\n",
    "            if not exclude_stopwords or word.lower() not in stopwords:\n",
    "                filtered_words.append(word.lower())\n",
    "                filtered_positions.append((word, start, end))\n",
    "    \n",
    "    if not filtered_words:\n",
    "        return document, {'replacements': [], 'message': 'No words to replace'}\n",
    "    \n",
    "    # Calculate TF-IDF\n",
    "    if corpus is None:\n",
    "        # Use only the input document\n",
    "        corpus = [document]\n",
    "    \n",
    "    # Create TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer(lowercase=True, token_pattern=r'\\b\\w+\\b')\n",
    "    \n",
    "    # Fit and transform\n",
    "    try:\n",
    "        tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        \n",
    "        # Get TF-IDF scores for words in the document\n",
    "        if len(corpus) == 1:\n",
    "            # Single document case\n",
    "            doc_scores = tfidf_matrix[0].toarray()[0]\n",
    "        else:\n",
    "            # Find which document in corpus matches (use first for simplicity)\n",
    "            doc_scores = tfidf_matrix[0].toarray()[0]\n",
    "        \n",
    "        # Create word to score mapping\n",
    "        word_scores = {}\n",
    "        for word in filtered_words:\n",
    "            if word in feature_names:\n",
    "                idx = list(feature_names).index(word)\n",
    "                word_scores[word] = doc_scores[idx]\n",
    "            else:\n",
    "                word_scores[word] = 0.0\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Fallback to simple TF if TF-IDF fails\n",
    "        word_counts = Counter(filtered_words)\n",
    "        total_words = len(filtered_words)\n",
    "        word_scores = {word: count / total_words for word, count in word_counts.items()}\n",
    "    \n",
    "    # Select words to replace\n",
    "    if num_words_to_replace is not None:\n",
    "        # Select top N words by TF-IDF score\n",
    "        sorted_words = sorted(word_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        words_to_replace = [word for word, score in sorted_words[:num_words_to_replace]]\n",
    "    elif tfidf_threshold is not None:\n",
    "        # Select words above threshold\n",
    "        words_to_replace = [word for word, score in word_scores.items() \n",
    "                           if score >= tfidf_threshold]\n",
    "    else:\n",
    "        # Default: replace top 10% of words\n",
    "        num_to_replace = max(1, len(filtered_words) // 10)\n",
    "        sorted_words = sorted(word_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        words_to_replace = [word for word, score in sorted_words[:num_to_replace]]\n",
    "    \n",
    "    if not words_to_replace:\n",
    "        return document, {'replacements': [], 'message': 'No words selected for replacement'}\n",
    "    \n",
    "    # Create a copy of the document to modify\n",
    "    result_doc = document\n",
    "    replacements_made = []\n",
    "    \n",
    "    # Process words in reverse order to preserve positions\n",
    "    # Sort positions in reverse to avoid index shifting issues\n",
    "    words_to_replace_set = set(words_to_replace)\n",
    "    \n",
    "    for original_word, start, end in reversed(filtered_positions):\n",
    "        if original_word.lower() in words_to_replace_set:\n",
    "            # Create masked sentence\n",
    "            # Find the sentence context around this word\n",
    "            sentence_start = max(0, result_doc.rfind('.', 0, start))\n",
    "            sentence_end = result_doc.find('.', end)\n",
    "            if sentence_end == -1:\n",
    "                sentence_end = len(result_doc)\n",
    "            \n",
    "            sentence = result_doc[sentence_start:sentence_end].strip()\n",
    "            if sentence_start > 0:\n",
    "                sentence = sentence.lstrip('.').strip()\n",
    "            \n",
    "            # Create masked version\n",
    "            masked_sentence = sentence[:start - sentence_start] + '<mask>' + sentence[end - sentence_start:]\n",
    "            \n",
    "            # Get replacement from MLM\n",
    "            try:\n",
    "                predictions = mlm_pipeline(masked_sentence)\n",
    "                if predictions and len(predictions) >= top_k:\n",
    "                    replacement = predictions[top_k - 1]['token_str'].strip()\n",
    "                    \n",
    "                    # Preserve case if requested\n",
    "                    if preserve_case:\n",
    "                        if original_word[0].isupper():\n",
    "                            replacement = replacement.capitalize()\n",
    "                    \n",
    "                    # Replace in document\n",
    "                    result_doc = result_doc[:start] + replacement + result_doc[end:]\n",
    "                    \n",
    "                    replacements_made.append({\n",
    "                        'original': original_word,\n",
    "                        'replacement': replacement,\n",
    "                        'position': start,\n",
    "                        'score': word_scores.get(original_word.lower(), 0.0),\n",
    "                        'mlm_score': predictions[top_k - 1]['score']\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                # Skip if MLM fails for this word\n",
    "                continue\n",
    "    \n",
    "    return result_doc, {\n",
    "        'replacements': replacements_made,\n",
    "        'num_replacements': len(replacements_made),\n",
    "        'words_selected': words_to_replace\n",
    "    }\n",
    "\n",
    "\n",
    "# Using the MLM pipeline from your notebook\n",
    "mlm = pipeline('fill-mask')\n",
    "\n",
    "# Example with your document\n",
    "doc = \"\"\"Bombardier chief to leave company\n",
    "\n",
    "Shares in train and plane-making giant Bombardier have fallen to a 10-year low following the departure of its chief executive and two members of the board.\"\"\"\n",
    "\n",
    "# Option 1: Using TF-IDF (requires sklearn)\n",
    "result, info = auto_mask_replace(\n",
    "    doc, \n",
    "    mlm, \n",
    "    num_words_to_replace=5,  # Replace top 5 TF-IDF words\n",
    "    top_k=1  # Use the best prediction\n",
    ")\n",
    "\n",
    "print(\"Original:\", doc)\n",
    "print(\"\\nModified:\", result)\n",
    "print(\"\\nReplacements made:\")\n",
    "for r in info['replacements']:\n",
    "    print(f\"  '{r['original']}' -> '{r['replacement']}' (TF-IDF: {r['score']:.4f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa4b074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
